{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"컨브넷.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyORWlr7x1spzeI6cwT3hjd4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"stIQyAcHxxX0","executionInfo":{"status":"ok","timestamp":1637204050166,"user_tz":-540,"elapsed":415,"user":{"displayName":"원용재","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07910673243591029153"}}},"source":["from keras import layers, models"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hwImluPhx3Lm","executionInfo":{"status":"ok","timestamp":1637201813334,"user_tz":-540,"elapsed":5922,"user":{"displayName":"원용재","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07910673243591029153"}},"outputId":"55af214a-b37a-43d7-eb0c-61b5c537bd11"},"source":["model = models.Sequential()\n","\n","model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.MaxPool2D(2, 2))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","\n","model.summary()"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 26, 26, 32)        320       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n","                                                                 \n","=================================================================\n","Total params: 55,744\n","Trainable params: 55,744\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"UFCydHHPzTdT","executionInfo":{"status":"ok","timestamp":1637201813335,"user_tz":-540,"elapsed":11,"user":{"displayName":"원용재","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07910673243591029153"}}},"source":["# Conv2D 와 MaxPooling2D 층의 출력은 (높이, 너비, 채널) 크기의 3D 텐서\n","# 높이와 너비 차원은 네트워크가 깊어질수록 작아지는 경향이 있음\n","# 채널의 수는 Conv2D 층에 전달된 첫 번째 매개변수에 의해 조절 (32개 or 64개)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"atFvKxaAy2lO","executionInfo":{"status":"ok","timestamp":1637201813335,"user_tz":-540,"elapsed":10,"user":{"displayName":"원용재","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07910673243591029153"}},"outputId":"2a00a714-0021-4534-aa96-1e390f09c8a6"},"source":["# 마지막 층의 (3, 3, 64) 크기인 출력 텐서를 완전 연결 네트워크에 주입\n","# 해당 네트워크는 이미 익숙하게 봤던 Dense 층을 쌓은 분류기\n","# 이 분류기는 1D 벡터를 처리하는데, 이전 층의 출력이 3D 텐서\n","# 먼저 3D 출력을 1D 텐서로 펼쳐야 하므로 몇 개의 Dense를 추가\n","\n","model.add(layers.Flatten())\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","model.summary()"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 26, 26, 32)        320       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n","                                                                 \n"," flatten (Flatten)           (None, 576)               0         \n","                                                                 \n"," dense (Dense)               (None, 64)                36928     \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 93,322\n","Trainable params: 93,322\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g1mvKrTazOC7","executionInfo":{"status":"ok","timestamp":1637201897443,"user_tz":-540,"elapsed":84116,"user":{"displayName":"원용재","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07910673243591029153"}},"outputId":"e1a6842b-3586-48b8-8a46-4da41532ea1c"},"source":["import tensorflow.keras\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","train_images = train_images.reshape((60000, 28, 28, 1))\n","train_images = train_images.astype('float32') / 255\n","\n","test_images = test_images.reshape((10000, 28, 28, 1))\n","test_images = test_images.astype('float32') / 255\n","\n","train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)\n","\n","model.compile(optimizer='rmsprop',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","model.fit(train_images, train_labels, epochs=5, batch_size=64)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n","Epoch 1/5\n","938/938 [==============================] - 40s 10ms/step - loss: 0.1665 - accuracy: 0.9474\n","Epoch 2/5\n","938/938 [==============================] - 9s 10ms/step - loss: 0.0463 - accuracy: 0.9855\n","Epoch 3/5\n","938/938 [==============================] - 10s 10ms/step - loss: 0.0329 - accuracy: 0.9897\n","Epoch 4/5\n","938/938 [==============================] - 10s 10ms/step - loss: 0.0245 - accuracy: 0.9923\n","Epoch 5/5\n","938/938 [==============================] - 10s 10ms/step - loss: 0.0191 - accuracy: 0.9942\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f93f0587b50>"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cKpN04UZ0zV7","executionInfo":{"status":"ok","timestamp":1637201906475,"user_tz":-540,"elapsed":2056,"user":{"displayName":"원용재","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07910673243591029153"}},"outputId":"ee29db4d-be64-42eb-afd8-7056a16fcca3"},"source":["test_loss, test_acc = model.evaluate(test_images, test_labels)\n","test_acc"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 2s 5ms/step - loss: 0.0233 - accuracy: 0.9932\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9932000041007996"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lHi27WUi9p2-","executionInfo":{"status":"ok","timestamp":1637204189562,"user_tz":-540,"elapsed":244,"user":{"displayName":"원용재","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07910673243591029153"}},"outputId":"fed3c0fb-0e81-4915-f622-2cfd07e06da7"},"source":["# 최대 풀링 연산\n","\n","model_no_max_pool = models.Sequential()\n","model_no_max_pool.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28,1)))\n","model_no_max_pool.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model_no_max_pool.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","\n","model_no_max_pool.summary()"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_3 (Conv2D)           (None, 26, 26, 32)        320       \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 24, 24, 64)        18496     \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 22, 22, 64)        36928     \n","                                                                 \n","=================================================================\n","Total params: 55,744\n","Trainable params: 55,744\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"UANSMVCX-V8H"},"source":[""],"execution_count":null,"outputs":[]}]}